from __future__ import annotations

from pathlib import Path
import sqlite3
import random
from datetime import datetime

import pandas as pd
import streamlit as st
import streamlit.components.v1 as components


# =============================
# ãƒ‘ã‚¹è¨­å®šï¼ˆapp.pyã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«CSVã‚’ç½®ãæƒ³å®šï¼‰
# =============================
APP_DIR = Path(__file__).resolve().parent

WORD_FILES = {
    "A1": APP_DIR / "CEFR-J A1ï¼ˆå…¥é–€ï¼‰.csv",
    "A2": APP_DIR / "CEFR-J A2ï¼ˆåŸºç¤ï¼‰.csv",
    "B1": APP_DIR / "CEFR-J B1ï¼ˆä¸­ç´šï¼‰.csv",
    "B2": APP_DIR / "CEFR-J B2ï¼ˆæº–ä¸Šç´šï¼‰.csv",
}

GRAMMAR_FILES = {
    "A1": APP_DIR / "è‹±å’Œè¾æ›¸_grammars_a1.csv",
    "A2": APP_DIR / "è‹±å’Œè¾æ›¸_grammars_a2.csv",
    "B1": APP_DIR / "è‹±å’Œè¾æ›¸_grammars_b1.csv",
    "B2": APP_DIR / "è‹±å’Œè¾æ›¸_grammars_b2.csv",
}

DB_PATH = APP_DIR / "progress.db"


# =============================
# DB
# =============================
def get_conn() -> sqlite3.Connection:
    conn = sqlite3.connect(DB_PATH)
    conn.execute("PRAGMA journal_mode=WAL;")
    return conn


def init_db() -> None:
    conn = get_conn()
    cur = conn.cursor()

    # å˜èªã‚¹ã‚³ã‚¢ï¼ˆmode=1..5ï¼‰
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS word_scores (
            level TEXT NOT NULL,
            headword TEXT NOT NULL,
            mode INTEGER NOT NULL,
            score INTEGER NOT NULL,      -- 0/5/10 or åˆæœŸ1
            attempts INTEGER NOT NULL,
            updated_at TEXT NOT NULL,
            PRIMARY KEY (level, headword, mode)
        )
        """
    )

    # æ–‡æ³•ã€Œèª­ã‚“ã ï¼ã€ç®¡ç†
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS grammar_reads (
            level TEXT NOT NULL,
            name TEXT NOT NULL,
            read_count INTEGER NOT NULL,
            last_read_at TEXT NOT NULL,
            PRIMARY KEY (level, name)
        )
        """
    )

    conn.commit()
    conn.close()


def now_iso() -> str:
    return datetime.now().isoformat(timespec="seconds")


def get_word_mode_score(level: str, headword: str, mode: int) -> tuple[int, int]:
    """(score, attempts) / ç„¡ã‘ã‚Œã°åˆæœŸ(1,0)"""
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        "SELECT score, attempts FROM word_scores WHERE level=? AND headword=? AND mode=?",
        (level, headword, mode),
    )
    row = cur.fetchone()
    conn.close()
    if row is None:
        return (1, 0)
    return (int(row[0]), int(row[1]))


def set_word_mode_score(level: str, headword: str, mode: int, score: int) -> None:
    prev_score, prev_attempts = get_word_mode_score(level, headword, mode)
    attempts = prev_attempts + 1

    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        INSERT INTO word_scores(level, headword, mode, score, attempts, updated_at)
        VALUES (?, ?, ?, ?, ?, ?)
        ON CONFLICT(level, headword, mode)
        DO UPDATE SET score=excluded.score, attempts=excluded.attempts, updated_at=excluded.updated_at
        """,
        (level, headword, mode, int(score), int(attempts), now_iso()),
    )
    conn.commit()
    conn.close()


def get_word_total_score(level: str, headword: str) -> int:
    # mode 1..5ï¼ˆç„¡ã„ã‚‚ã®ã¯1ï¼‰
    total = 0
    for m in range(1, 6):
        s, _ = get_word_mode_score(level, headword, m)
        total += s
    return total


def get_all_word_totals(level: str, headwords: list[str]) -> dict[str, int]:
    """
    DBã‹ã‚‰ã¾ã¨ã‚ã¦å–å¾—ï¼ˆå­˜åœ¨ã—ãªã„modeã¯1æ‰±ã„ï¼‰
    """
    # åˆæœŸå€¤ã¯5ï¼ˆ1Ã—5ï¼‰
    totals = {hw: 5 for hw in headwords}

    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT headword, mode, score
        FROM word_scores
        WHERE level=? 
        """,
        (level,),
    )
    rows = cur.fetchall()
    conn.close()

    # ã¾ãšå…¨éƒ¨ 1Ã—5 ã¨ã—ã¦ãŠã„ã¦ã€å­˜åœ¨ã™ã‚‹ mode ã‚’å·®ã—æ›¿ãˆ
    # ãŸã ã—ã€æ—¢ã«åˆæœŸ1ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã®ã§ã€Œ(score - 1)ã€åˆ†ã ã‘åŠ ç®—ã™ã‚‹
    for hw, mode, score in rows:
        if hw in totals and 1 <= int(mode) <= 5:
            totals[hw] += int(score) - 1

    return totals


def mark_grammar_read(level: str, name: str) -> None:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        "SELECT read_count FROM grammar_reads WHERE level=? AND name=?",
        (level, name),
    )
    row = cur.fetchone()
    if row is None:
        read_count = 1
        cur.execute(
            "INSERT INTO grammar_reads(level, name, read_count, last_read_at) VALUES (?, ?, ?, ?)",
            (level, name, read_count, now_iso()),
        )
    else:
        read_count = int(row[0]) + 1
        cur.execute(
            "UPDATE grammar_reads SET read_count=?, last_read_at=? WHERE level=? AND name=?",
            (read_count, now_iso(), level, name),
        )
    conn.commit()
    conn.close()


def get_grammar_read_stats(level: str, names: list[str]) -> tuple[int, int]:
    """
    (read_unique_count, total)
    """
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT name FROM grammar_reads WHERE level=?", (level,))
    read_names = {r[0] for r in cur.fetchall()}
    conn.close()
    total = len(names)
    read_unique = sum(1 for n in names if n in read_names)
    return read_unique, total


# =============================
# CSVãƒ­ãƒ¼ãƒ‰
# =============================
def must_exist(path: Path) -> None:
    if not path.exists():
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")
        st.stop()


@st.cache_data
def load_words(level: str) -> pd.DataFrame:
    path = WORD_FILES[level]
    must_exist(path)
    df = pd.read_csv(path, encoding="utf-8-sig").fillna("")

    # ã‚ˆãã‚ã‚‹åˆ—åã«å¯„ã›ã‚‹ï¼ˆå­˜åœ¨ã—ãªã„åˆ—ã¯ç©ºã§ä½œã‚‹ï¼‰
    # ã“ã“ãŒâ€œä¿é™ºâ€ã€‚ã‚ãªãŸã®CSVåˆ—ãŒå¤šå°‘é•ã£ã¦ã‚‚å‹•ãã‚ˆã†ã«ã™ã‚‹ã€‚
    candidates = {
        "headword": ["headword", "word", "lemma"],
        "pos": ["pos", "part_of_speech"],
        "meaning_ja": ["meaning_ja", "meaning", "ja", "japanese"],
        "ipa": ["ipa", "pronunciation"],
        "example_sentence": ["example_sentence", "example", "sentence_en", "en_sentence"],
        "translated_sentence": ["translated_sentence", "translation", "sentence_ja", "ja_sentence"],
    }

    def pick(colkey: str) -> str:
        for c in candidates[colkey]:
            if c in df.columns:
                return c
        return ""

    # æ¨™æº–åˆ—åã¸æ­£è¦åŒ–ã—ãŸDataFrameã‚’è¿”ã™
    out = pd.DataFrame()
    for key in candidates.keys():
        src = pick(key)
        out[key] = df[src] if src else ""

    # headwordãŒç©ºã®è¡Œã‚’é™¤å¤–
    out = out[out["headword"].astype(str).str.strip() != ""].reset_index(drop=True)
    return out


@st.cache_data
def load_grammars(level: str) -> pd.DataFrame:
    path = GRAMMAR_FILES[level]
    must_exist(path)
    df = pd.read_csv(path, encoding="utf-8-sig").fillna("")

    candidates = {
        "name": ["name", "title"],
        "summary": ["summary"],
        "explanation": ["explanation", "detail", "description"],
        "original": ["original", "example", "en"],
        "translation": ["translation", "ja"],
    }

    def pick(colkey: str) -> str:
        for c in candidates[colkey]:
            if c in df.columns:
                return c
        return ""

    out = pd.DataFrame()
    for key in candidates.keys():
        src = pick(key)
        out[key] = df[src] if src else ""

    out = out[out["name"].astype(str).str.strip() != ""].reset_index(drop=True)
    return out


# =============================
# å‡ºé¡Œãƒ­ã‚¸ãƒƒã‚¯
# =============================
MODE_LABELS = {
    1: "â‘  è‹±å˜èª â†’ æ—¥æœ¬èªï¼ˆå˜èª/æ„å‘³ï¼‰",
    2: "â‘¡ æ—¥æœ¬èªï¼ˆå˜èª/æ„å‘³ï¼‰ â†’ è‹±å˜èª",
    3: "â‘¢ è‹±ä¾‹æ–‡ â†’ æ—¥æœ¬ä¾‹æ–‡",
    4: "â‘£ æ—¥æœ¬ä¾‹æ–‡ â†’ è‹±ä¾‹æ–‡",
    5: "â‘¤ ãƒªã‚¹ãƒ‹ãƒ³ã‚°ï¼ˆè‹±ï¼‰â†’ è‹±æ–‡ï¼†æ—¥æœ¬æ–‡ï¼ˆâ€»ãƒ–ãƒ©ã‚¦ã‚¶éŸ³å£°ï¼‰",
}

def choose_word_weighted(level: str, df_words: pd.DataFrame) -> int:
    """
    (51 - å˜èªã®5æŒ‡æ¨™åˆè¨ˆ) ã‚’é‡ã¿ã«ã—ã¦å˜èªindexã‚’é¸ã¶
    """
    headwords = df_words["headword"].astype(str).tolist()
    totals = get_all_word_totals(level, headwords)  # å„å˜èªã®5æŒ‡æ¨™åˆè¨ˆï¼ˆåˆæœŸ5ï¼‰

    weights = []
    for hw in headwords:
        total = totals.get(hw, 5)
        w = 51 - total  # ä»•æ§˜ã®å¼
        if w < 0:
            w = 0
        weights.append(w)

    # å…¨éƒ¨0ã«ãªã£ãŸå ´åˆã¯å‡ç­‰
    if sum(weights) == 0:
        return random.randrange(len(df_words))

    idx = random.choices(range(len(df_words)), weights=weights, k=1)[0]
    return int(idx)


def pick_mode(enabled_modes: list[int]) -> int:
    return random.choice(enabled_modes)


def speak_button(text: str, button_label: str = "â–¶ å†ç”Ÿ") -> None:
    """
    ãƒ–ãƒ©ã‚¦ã‚¶å´ã® SpeechSynthesis ã‚’ä½¿ã£ã¦è‹±èªTTSï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§ã‚‚å‹•ãç’°å¢ƒãŒå¤šã„ï¼‰
    """
    safe = text.replace("\\", "\\\\").replace("`", "\\`").replace("\n", " ")
    html = f"""
    <button onclick="
      const u = new SpeechSynthesisUtterance(`{safe}`);
      u.lang = 'en-US';
      speechSynthesis.cancel();
      speechSynthesis.speak(u);
    " style="padding:8px 12px; border-radius:8px; border:1px solid #ccc; cursor:pointer;">
      {button_label}
    </button>
    """
    components.html(html, height=60)


# =============================
# UI
# =============================
st.set_page_config(page_title="CEFR è‹±èªæ•™æ", layout="centered")
init_db()

st.title("CEFR ãƒ¬ãƒ™ãƒ«åˆ¥ è‹±èªæ•™æï¼ˆå˜èªãƒ†ã‚¹ãƒˆ + æ–‡æ³•ï¼‰")

tab_words, tab_grammar = st.tabs(["ğŸ§  å˜èªãƒ†ã‚¹ãƒˆ", "ğŸ“˜ æ–‡æ³•"])


# -----------------------------
# å˜èªãƒ†ã‚¹ãƒˆ
# -----------------------------
with tab_words:
    level = st.selectbox("ãƒ¬ãƒ™ãƒ«", ["A1", "A2", "B1", "B2"], key="word_level")
    dfw = load_words(level)
    st.caption(f"å˜èªæ•°: {len(dfw)}")

    # --- å‡ºé¡Œè¨­å®šï¼ˆèµ·å‹•ç›´å¾Œã¯å•é¡Œã‚’å‡ºã•ãªã„ï¼‰ ---
    st.markdown("### å‡ºé¡Œè¨­å®š")
    include_listening = st.checkbox("â‘¤ ãƒªã‚¹ãƒ‹ãƒ³ã‚°ã‚‚å«ã‚ã‚‹", value=False)
    enabled_modes = [1, 2, 3, 4] + ([5] if include_listening else [])

    # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ ---
    if "started" not in st.session_state:
        st.session_state.started = False
    if "q_idx" not in st.session_state:
        st.session_state.q_idx = None
    if "q_mode" not in st.session_state:
        st.session_state.q_mode = None
    if "revealed" not in st.session_state:
        st.session_state.revealed = False

    def new_question():
        st.session_state.revealed = False
        st.session_state.q_idx = choose_word_weighted(level, dfw)
        st.session_state.q_mode = pick_mode(enabled_modes)

    # --- ã¾ãšå‡ºé¡Œãƒœã‚¿ãƒ³ã‚’æŠ¼ã•ã›ã‚‹ ---
    c_start, c_reset = st.columns([1, 1])
    with c_start:
        if st.button("å‡ºé¡Œ", type="primary"):
            st.session_state.started = True
            new_question()
    with c_reset:
        if st.button("å‡ºé¡Œã‚’çµ‚äº†ï¼ˆãƒªã‚»ãƒƒãƒˆï¼‰"):
            st.session_state.started = False
            st.session_state.q_idx = None
            st.session_state.q_mode = None
            st.session_state.revealed = False

    # --- å‡ºé¡Œé–‹å§‹å‰ã¯ã“ã“ã§æ­¢ã‚ã‚‹ ---
    if not st.session_state.started or st.session_state.q_idx is None:
        st.info("éŸ³å£°ã®æœ‰ç„¡ã‚’é¸ã‚“ã§ã‹ã‚‰ã€Œå‡ºé¡Œã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
    else:
        # --- ã“ã“ã‹ã‚‰å…ˆã¯ã€Œå•é¡Œè¡¨ç¤ºã€ ---
        row = dfw.iloc[int(st.session_state.q_idx)]
        hw = str(row["headword"])
        pos = str(row.get("pos", ""))
        meaning_ja = str(row.get("meaning_ja", ""))
        ipa = str(row.get("ipa", ""))
        ex_en = str(row.get("example_sentence", ""))
        ex_ja = str(row.get("translated_sentence", ""))

        mode = int(st.session_state.q_mode)

        st.divider()
        st.markdown(f"### å•é¡Œï¼š{MODE_LABELS[mode]}")

        # å•é¡Œæç¤ºï¼ˆç­”ãˆã¯å‡ºã•ãªã„ï¼‰
        if mode == 1:
            st.subheader(hw)
            if ipa:
                st.text(f"IPA: {ipa}")
            if pos:
                st.text(f"å“è©: {pos}")

        elif mode == 2:
            st.subheader("ï¼ˆæ—¥æœ¬èªï¼‰")
            st.write(meaning_ja)

        elif mode == 3:
            st.subheader("ï¼ˆè‹±ä¾‹æ–‡ï¼‰")
            st.write(ex_en)

        elif mode == 4:
            st.subheader("ï¼ˆæ—¥æœ¬ä¾‹æ–‡ï¼‰")
            st.write(ex_ja)

        elif mode == 5:
            st.subheader("ï¼ˆãƒªã‚¹ãƒ‹ãƒ³ã‚°ï¼‰")
            if ex_en.strip():
                speak_button(ex_en, "â–¶ è‹±æ–‡ã‚’å†ç”Ÿ")
            else:
                st.info("ã“ã®å˜èªã¯ä¾‹æ–‡ãŒç©ºãªã®ã§ã€ãƒªã‚¹ãƒ‹ãƒ³ã‚°å‡ºé¡ŒãŒé›£ã—ã„ã§ã™ã€‚åˆ¥å•é¡Œã«åˆ‡ã‚Šæ›¿ãˆã¦ãã ã•ã„ã€‚")

        # ã€Œç­”ãˆã‚’è¦‹ã‚‹ã€
        st.markdown("###")
        if st.button("ç­”ãˆã‚’è¦‹ã‚‹", type="primary"):
            st.session_state.revealed = True

        # å…¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¡¨ç¤ºï¼ˆç­”ãˆï¼‰
        if st.session_state.revealed:
            if st.button("æ¬¡ã®å•é¡Œ"):
                new_question()
                st.rerun()

            st.success("ç­”ãˆï¼ˆå…¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼‰")

            st.markdown("**è‹±å˜èª**")
            st.write(hw)
            if ipa:
                st.markdown("**IPA**")
                st.write(ipa)
            if pos:
                st.markdown("**å“è©**")
                st.write(pos)

            st.markdown("**æ—¥æœ¬èªï¼ˆå˜èª/æ„å‘³ï¼‰**")
            st.write(meaning_ja)

            st.markdown("**è‹±ä¾‹æ–‡**")
            st.write(ex_en)

            st.markdown("**æ—¥æœ¬ä¾‹æ–‡**")
            st.write(ex_ja)

            # è‡ªå·±è©•ä¾¡ â†’ ã‚¹ã‚³ã‚¢æ›´æ–°
            st.markdown("### è‡ªå·±è©•ä¾¡ï¼ˆã“ã®ãƒ¢ãƒ¼ãƒ‰ã®ã‚¹ã‚³ã‚¢ã‚’æ›´æ–°ï¼‰")
            c1, c2, c3, c4 = st.columns([1, 1, 1, 2])
            with c1:
                if st.button("æ­£è§£ï¼ˆ10ï¼‰"):
                    set_word_mode_score(level, hw, mode, 10)
                    st.toast("è¨˜éŒ²ã—ã¾ã—ãŸ âœ…")
            with c2:
                if st.button("å¾®å¦™ï¼ˆ5ï¼‰"):
                    set_word_mode_score(level, hw, mode, 5)
                    st.toast("è¨˜éŒ²ã—ã¾ã—ãŸ âœ…")
            with c3:
                if st.button("ä¸æ­£è§£ï¼ˆ0ï¼‰"):
                    set_word_mode_score(level, hw, mode, 0)
                    st.toast("è¨˜éŒ²ã—ã¾ã—ãŸ âœ…")
            with c4:
                if st.button("ã“ã®å˜èªã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ›´æ–°ãªã—ï¼‰"):
                    st.toast("è¨˜éŒ²ã—ã¾ã—ãŸ âœ…")

            # ç¾åœ¨ã‚¹ã‚³ã‚¢ã®è¦‹ãˆã‚‹åŒ–
            m_scores = []
            for m in range(1, 6):
                s, a = get_word_mode_score(level, hw, m)
                m_scores.append((m, s, a))
            total = sum(s for _, s, _ in m_scores)

            with st.expander("ã“ã®å˜èªã®ã‚¹ã‚³ã‚¢çŠ¶æ³ï¼ˆ1ã€œ5ï¼‰"):
                st.write({f"mode{m}": {"score": s, "attempts": a} for (m, s, a) in m_scores})
                st.write(f"åˆè¨ˆï¼ˆ5æŒ‡æ¨™ï¼‰: {total} / 50ï¼ˆåˆæœŸã¯5ï¼‰")
                st.caption("é‡ã¿ = 51 - åˆè¨ˆï¼ˆä»•æ§˜ã©ãŠã‚Šï¼‰ â†’ åˆè¨ˆãŒé«˜ã„ã»ã©å‡ºã«ãããªã‚Šã¾ã™ã€‚")


# -----------------------------
# æ–‡æ³•
# -----------------------------
with tab_grammar:
    level_g = st.selectbox("ãƒ¬ãƒ™ãƒ«", ["A1", "A2", "B1", "B2"], key="grammar_level")
    dfg = load_grammars(level_g)
    names = dfg["name"].astype(str).tolist()

    # çŠ¶æ…‹
    if "g_view" not in st.session_state:
        st.session_state.g_view = "index"  # "index" or "reader"
    if "g_idx" not in st.session_state:
        st.session_state.g_idx = 1

    # èª­äº†çµ±è¨ˆ
    read_unique, total_g = get_grammar_read_stats(level_g, names)
    st.caption(f"æ–‡æ³•é …ç›®æ•°: {total_g} / èª­äº†ï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯ï¼‰: {read_unique}")

    # ----- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ -----
    if st.session_state.g_view == "index":
        st.markdown("### æ–‡æ³•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹")

        q = st.text_input("æ¤œç´¢ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã®ä¸€éƒ¨ï¼‰", "")
        show = dfg
        if q.strip():
            show = dfg[dfg["name"].astype(str).str.contains(q, case=False, na=False)]

        titles = show["name"].astype(str).tolist()
        if not titles:
            st.warning("æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            st.stop()

        placeholder = "ï¼ˆé …ç›®ã‚’é¸ã‚“ã§ãã ã•ã„ï¼‰"
        options = [placeholder] + titles
        selected = st.selectbox("é–‹ãé …ç›®", options, index=0, key="grammar_index_select")

        if st.button("ã“ã®é …ç›®ã‚’é–‹ã", type="primary", key="grammar_open_btn"):
            if selected == placeholder:
                st.warning("é …ç›®ã‚’é¸ã‚“ã§ã‹ã‚‰ã€Œã“ã®é …ç›®ã‚’é–‹ãã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
            else:
                st.session_state.g_idx = int(dfg.index[dfg["name"].astype(str) == selected][0]) + 1
                st.session_state.g_view = "reader"
                st.rerun()

        st.stop()

    # ----- ãƒªãƒ¼ãƒ€ãƒ¼ -----
    if st.button("âŸµ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¸æˆ»ã‚‹", key="grammar_back_to_index"):
        st.session_state.g_view = "index"
        st.stop()

    n = len(dfg)
    if n == 0:
        st.warning("æ–‡æ³•ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚CSVã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    c_prev, _, c_next = st.columns([1, 2, 1])
    with c_prev:
        if st.button("â† æˆ»ã‚‹", key="grammar_prev"):
            st.session_state.g_idx = max(1, st.session_state.g_idx - 1)
    with c_next:
        if st.button("æ¬¡ã¸ â†’", key="grammar_next"):
            st.session_state.g_idx = min(n, st.session_state.g_idx + 1)

    idx1 = st.number_input("é …ç›®ç•ªå·", min_value=1, max_value=n, value=st.session_state.g_idx, step=1, key="grammar_number")
    st.session_state.g_idx = int(idx1)

    st.caption(f"{st.session_state.g_idx} / {n}")
    row = dfg.iloc[st.session_state.g_idx - 1]

    title = str(row.get("name", ""))
    summary = str(row.get("summary", ""))
    explanation = str(row.get("explanation", ""))
    original = str(row.get("original", ""))
    translation = str(row.get("translation", ""))

    st.subheader(title)
    if summary.strip():
        st.info(summary)

    if explanation.strip():
        st.markdown(explanation)
    else:
        st.write("ï¼ˆè§£èª¬ãªã—ï¼‰")

    st.markdown("**ä¾‹æ–‡**")
    st.write(original)
    st.write("â€”")
    st.write(translation)

    if st.button("èª­ã‚“ã ï¼", key="grammar_read", type="primary"):
        mark_grammar_read(level_g, title)
        st.toast("è¨˜éŒ²ã—ã¾ã—ãŸ âœ…")
